{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "178c9a45",
   "metadata": {},
   "source": [
    "# Baseball Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee48bce",
   "metadata": {},
   "source": [
    "## OG algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cf10b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc31df68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1 h</th>\n",
       "      <th>m2 h</th>\n",
       "      <th>m3 h</th>\n",
       "      <th>m4 h</th>\n",
       "      <th>m1 a</th>\n",
       "      <th>m2 a</th>\n",
       "      <th>m3 a</th>\n",
       "      <th>m4 a</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2763.000000</td>\n",
       "      <td>2763.000000</td>\n",
       "      <td>2763.000000</td>\n",
       "      <td>2763.000000</td>\n",
       "      <td>2763.000000</td>\n",
       "      <td>2763.000000</td>\n",
       "      <td>2763.000000</td>\n",
       "      <td>2763.000000</td>\n",
       "      <td>2763.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.377351</td>\n",
       "      <td>0.042599</td>\n",
       "      <td>-0.125212</td>\n",
       "      <td>0.160548</td>\n",
       "      <td>0.384202</td>\n",
       "      <td>0.020174</td>\n",
       "      <td>-0.103820</td>\n",
       "      <td>0.228418</td>\n",
       "      <td>0.534202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.541160</td>\n",
       "      <td>0.848823</td>\n",
       "      <td>1.228167</td>\n",
       "      <td>2.527689</td>\n",
       "      <td>1.738104</td>\n",
       "      <td>0.848673</td>\n",
       "      <td>1.194767</td>\n",
       "      <td>2.366799</td>\n",
       "      <td>0.498919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-25.770000</td>\n",
       "      <td>-2.390000</td>\n",
       "      <td>-6.251034</td>\n",
       "      <td>-83.900000</td>\n",
       "      <td>-48.690000</td>\n",
       "      <td>-2.310000</td>\n",
       "      <td>-6.368462</td>\n",
       "      <td>-84.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.220000</td>\n",
       "      <td>-0.560000</td>\n",
       "      <td>-0.730974</td>\n",
       "      <td>-0.638366</td>\n",
       "      <td>-0.170000</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-0.719985</td>\n",
       "      <td>-0.564976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>-0.003274</td>\n",
       "      <td>0.427595</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.401232</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.160000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.489338</td>\n",
       "      <td>1.308438</td>\n",
       "      <td>1.160000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.531609</td>\n",
       "      <td>1.315699</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.920000</td>\n",
       "      <td>1.920000</td>\n",
       "      <td>24.879934</td>\n",
       "      <td>5.920000</td>\n",
       "      <td>5.960000</td>\n",
       "      <td>1.760000</td>\n",
       "      <td>9.921471</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              m1 h         m2 h         m3 h         m4 h         m1 a  \\\n",
       "count  2763.000000  2763.000000  2763.000000  2763.000000  2763.000000   \n",
       "mean      0.377351     0.042599    -0.125212     0.160548     0.384202   \n",
       "std       1.541160     0.848823     1.228167     2.527689     1.738104   \n",
       "min     -25.770000    -2.390000    -6.251034   -83.900000   -48.690000   \n",
       "25%      -0.220000    -0.560000    -0.730974    -0.638366    -0.170000   \n",
       "50%       0.530000     0.130000    -0.003274     0.427595     0.550000   \n",
       "75%       1.160000     0.650000     0.489338     1.308438     1.160000   \n",
       "max       5.920000     1.920000    24.879934     5.920000     5.960000   \n",
       "\n",
       "              m2 a         m3 a         m4 a       winner  \n",
       "count  2763.000000  2763.000000  2763.000000  2763.000000  \n",
       "mean      0.020174    -0.103820     0.228418     0.534202  \n",
       "std       0.848673     1.194767     2.366799     0.498919  \n",
       "min      -2.310000    -6.368462   -84.300000     0.000000  \n",
       "25%      -0.600000    -0.719985    -0.564976     0.000000  \n",
       "50%       0.040000     0.000000     0.401232     1.000000  \n",
       "75%       0.650000     0.531609     1.315699     1.000000  \n",
       "max       1.760000     9.921471     6.100000     1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grab data\n",
    "data_path = 'og_algo/train.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "testing_path = 'og_algo/data21.csv'\n",
    "testing = pd.read_csv(testing_path)\n",
    "\n",
    "#print\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b80b6740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y is the value we are trying to predict\n",
    "train_y = data.winner\n",
    "#these are the variables we are using to make the prediction\n",
    "features = ['m1 h', 'm2 h', 'm3 h', 'm4 h', 'm1 a', 'm2 a', 'm3 a', 'm4 a']\n",
    "train_X = data[features]\n",
    "\n",
    "val_y = testing.winner\n",
    "val_X = testing[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b07ad812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor: \n",
      "0.5132939438700148\n"
     ]
    }
   ],
   "source": [
    "#train_X, val_X, train_y, val_y = train_test_split(x, y, random_state = 1, test_size = 0.3)\n",
    "\n",
    "data_model = DecisionTreeRegressor(random_state=1)\n",
    "data_model.fit(train_X, train_y)\n",
    "\n",
    "# get predicted prices on validation data\n",
    "val_predictions = data_model.predict(val_X)\n",
    "print(\"Decision Tree Regressor: \")\n",
    "print(1 - mean_absolute_error(val_y, val_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d01da9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression: \n",
      "0.5146750369276218\n"
     ]
    }
   ],
   "source": [
    "random_model = RandomForestRegressor(random_state=1)\n",
    "random_model.fit(train_X, train_y)\n",
    "\n",
    "forest_preds = random_model.predict(val_X)\n",
    "print(\"Random Forest Regression: \")\n",
    "print(1 - mean_absolute_error(val_y, forest_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c131f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifer: \n",
      "0.5664697193500738\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "class_model = GradientBoostingClassifier(random_state=1)\n",
    "class_model.fit(train_X, train_y)\n",
    "\n",
    "class_preds = class_model.predict(val_X)\n",
    "print(\"Gradient Boosting Classifer: \")\n",
    "print(accuracy_score(val_y, class_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c72c75ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: \n",
      "0.5664697193500738\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(train_X, train_y)\n",
    "lr_preds = lr.predict(val_X)\n",
    "#print(mean_absolute_error(val_y, lr_preds))\n",
    "print(\"Logistic Regression: \")\n",
    "print(accuracy_score(val_y, lr_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d418b4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression w/ Pipeline: \n",
      "0.5664697193500738\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     LogisticRegression())\n",
    "\n",
    "pipe.fit(train_X, train_y)\n",
    "p_preds = pipe.predict(val_X)\n",
    "\n",
    "print(\"Logistic Regression w/ Pipeline: \")\n",
    "print(accuracy_score(val_y, p_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2fb05e",
   "metadata": {},
   "source": [
    "## Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90cc3960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f0e14ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hrs</th>\n",
       "      <th>hra</th>\n",
       "      <th>hsera</th>\n",
       "      <th>hr</th>\n",
       "      <th>hera</th>\n",
       "      <th>ars</th>\n",
       "      <th>ara</th>\n",
       "      <th>asera</th>\n",
       "      <th>ar</th>\n",
       "      <th>aera</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4027.000000</td>\n",
       "      <td>4027.000000</td>\n",
       "      <td>4027.000000</td>\n",
       "      <td>4027.000000</td>\n",
       "      <td>4027.000000</td>\n",
       "      <td>4027.000000</td>\n",
       "      <td>4027.000000</td>\n",
       "      <td>4027.000000</td>\n",
       "      <td>4027.000000</td>\n",
       "      <td>4027.000000</td>\n",
       "      <td>4027.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.640405</td>\n",
       "      <td>4.628354</td>\n",
       "      <td>4.459668</td>\n",
       "      <td>1.066056</td>\n",
       "      <td>4.301540</td>\n",
       "      <td>4.632575</td>\n",
       "      <td>4.635302</td>\n",
       "      <td>4.411378</td>\n",
       "      <td>1.064336</td>\n",
       "      <td>4.288438</td>\n",
       "      <td>0.535138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.512721</td>\n",
       "      <td>0.572279</td>\n",
       "      <td>1.797360</td>\n",
       "      <td>0.380181</td>\n",
       "      <td>1.478321</td>\n",
       "      <td>0.512028</td>\n",
       "      <td>0.570607</td>\n",
       "      <td>1.703785</td>\n",
       "      <td>0.377345</td>\n",
       "      <td>1.475169</td>\n",
       "      <td>0.498826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.410000</td>\n",
       "      <td>3.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.430000</td>\n",
       "      <td>3.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>4.190000</td>\n",
       "      <td>3.323864</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>3.440000</td>\n",
       "      <td>4.310000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>3.299255</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>3.440000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.650000</td>\n",
       "      <td>4.620000</td>\n",
       "      <td>4.224490</td>\n",
       "      <td>1.016393</td>\n",
       "      <td>4.160000</td>\n",
       "      <td>4.640000</td>\n",
       "      <td>4.640000</td>\n",
       "      <td>4.215886</td>\n",
       "      <td>1.016129</td>\n",
       "      <td>4.130000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.980000</td>\n",
       "      <td>5.060000</td>\n",
       "      <td>5.329428</td>\n",
       "      <td>1.254237</td>\n",
       "      <td>4.910000</td>\n",
       "      <td>4.970000</td>\n",
       "      <td>5.070000</td>\n",
       "      <td>5.302115</td>\n",
       "      <td>1.254391</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.030000</td>\n",
       "      <td>6.450000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.527778</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.420000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.558824</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               hrs          hra        hsera           hr         hera  \\\n",
       "count  4027.000000  4027.000000  4027.000000  4027.000000  4027.000000   \n",
       "mean      4.640405     4.628354     4.459668     1.066056     4.301540   \n",
       "std       0.512721     0.572279     1.797360     0.380181     1.478321   \n",
       "min       3.410000     3.040000     0.000000     0.369231     0.000000   \n",
       "25%       4.300000     4.190000     3.323864     0.805195     3.440000   \n",
       "50%       4.650000     4.620000     4.224490     1.016393     4.160000   \n",
       "75%       4.980000     5.060000     5.329428     1.254237     4.910000   \n",
       "max       6.030000     6.450000    18.000000     2.527778    18.000000   \n",
       "\n",
       "               ars          ara        asera           ar         aera  \\\n",
       "count  4027.000000  4027.000000  4027.000000  4027.000000  4027.000000   \n",
       "mean      4.632575     4.635302     4.411378     1.064336     4.288438   \n",
       "std       0.512028     0.570607     1.703785     0.377345     1.475169   \n",
       "min       3.430000     3.040000     0.000000     0.375000     0.000000   \n",
       "25%       4.310000     4.200000     3.299255     0.803922     3.440000   \n",
       "50%       4.640000     4.640000     4.215886     1.016129     4.130000   \n",
       "75%       4.970000     5.070000     5.302115     1.254391     4.900000   \n",
       "max       6.000000     6.420000    18.000000     2.558824    18.000000   \n",
       "\n",
       "            winner  \n",
       "count  4027.000000  \n",
       "mean      0.535138  \n",
       "std       0.498826  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned = ['hsera', 'asera', 'hera', 'aera']\n",
    "\n",
    "data_path = 'raw/train.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "for item in cleaned:\n",
    "    data.loc[data[item] > 18, item] = 18\n",
    "\n",
    "testing_path = 'raw/data21.csv'\n",
    "testing = pd.read_csv(testing_path)\n",
    "\n",
    "testing.loc[data[item] > 18, item] = 18\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "032be4b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'List' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jq/z17b57lx55q8y9sr8pv9c4140000gn/T/ipykernel_68790/2154161905.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDataFrameColumnTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTransformerMixin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mColumnTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/jq/z17b57lx55q8y9sr8pv9c4140000gn/T/ipykernel_68790/2154161905.py\u001b[0m in \u001b[0;36mDataFrameColumnTransformer\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDataFrameColumnTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTransformerMixin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mColumnTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'List' is not defined"
     ]
    }
   ],
   "source": [
    "class DataFrameColumnTransformer(TransformerMixin):\n",
    "    def __init__(self, stages):\n",
    "        self.col_trans = ColumnTransformer(stages)\n",
    "    \n",
    "    def fit(self, X: pd.DataFrame):\n",
    "        \"\"\" Runs our ColumnTransformer.fit() method \"\"\"\n",
    "        self.col_trans.fit(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\" Runs our ColumnTransformer.transform() method \"\"\"\n",
    "        output_arr = self.col_trans.transform(X)\n",
    "        \n",
    "        return self.to_dataframe(output_arr)\n",
    "    \n",
    "    def to_dataframe(self, arr: np.ndarray) -> pd.DataFrame:\n",
    "        \"\"\"Converts our output of ColumnTransformer into a DataFrame\"\"\"\n",
    "        feature_names = self.col_trans.get_feature_names_out()\n",
    "        \n",
    "        # Remove the \"__\" that ColumnTransformer adds to our feature names\n",
    "        # when we call self.col_trans.get_feature_names_out()\n",
    "        for i, name in enumerate(feature_names):\n",
    "            if '__' in name:\n",
    "                feature_names[i] = name.split('__', 1)[-1]\n",
    "        \n",
    "        # Creates a Pandas Dataframe\n",
    "        df = pd.DataFrame(arr, columns=feature_names)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84abc49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogTransformer(BaseEstimator, TransformerMixin): \n",
    "    def __init__(self):\n",
    "        self.feature_names = None\n",
    "    \n",
    "    def fit(self,\n",
    "            X: pd.DataFrame, \n",
    "            y: pd.DataFrame = None):\n",
    "        \n",
    "        # We don't need to set/learn any variables so\n",
    "        # we just need to return a reference to the object with 'self'\n",
    "        # If we dont return self the Pipeline class will throw errors\n",
    "        return self\n",
    "    \n",
    "    def transform(self,\n",
    "                  X: pd.DataFrame, \n",
    "                  y: pd.DataFrame = None) -> pd.DataFrame:\n",
    "        self.feature_names = X.columns\n",
    "        \n",
    "        return np.log1p(X)\n",
    "    \n",
    "    def get_feature_names_out(self, names=None):\n",
    "        return list(self.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4bcb1f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def before_pipeline(data):\n",
    "    passthrough_cols = data.drop(['hera', 'aera', 'hsera', 'asera'], axis=1).columns \n",
    "\n",
    "    # TODO 3.1\n",
    "    stages = [('pass', 'passthrough', passthrough_cols),\n",
    "              ('log', LogTransformer(), ['hera', 'aera', 'hsera', 'asera'])]\n",
    "\n",
    "    # TODO 3.2\n",
    "    before_pipe = DataFrameColumnTransformer(stages)\n",
    "    \n",
    "    # TODO 3.3\n",
    "    cleaner_df = before_pipe.fit_transform(data)\n",
    "    \n",
    "    return cleaner_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ce34226",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataFrameColumnTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jq/z17b57lx55q8y9sr8pv9c4140000gn/T/ipykernel_68790/1683411407.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbefore_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbefore_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#y is the value we are trying to predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwinner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/jq/z17b57lx55q8y9sr8pv9c4140000gn/T/ipykernel_68790/2854410022.py\u001b[0m in \u001b[0;36mbefore_pipeline\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# TODO 3.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mbefore_pipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrameColumnTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# TODO 3.3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataFrameColumnTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "data = before_pipeline(data)\n",
    "testing = before_pipeline(testing)\n",
    "\n",
    "#y is the value we are trying to predict\n",
    "train_y = data.winner\n",
    "#these are the variables we are using to make the prediction\n",
    "features = ['hrs', 'hra', 'hsera', 'hr', 'hera', 'ars', 'ara', 'asera', 'ar', 'aera']\n",
    "train_X = data[features]\n",
    "\n",
    "val_y = testing.winner\n",
    "val_X = testing[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "323f200c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: \n",
      "0.564237415477085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state  = 41)\n",
    "\n",
    "lr.fit(train_X, train_y)\n",
    "lr_preds = lr.predict(val_X)\n",
    "#print(mean_absolute_error(val_y, lr_preds))\n",
    "print(\"Logistic Regression: \")\n",
    "print(accuracy_score(val_y, lr_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36e01e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression w/ Pipeline: \n",
      "0.564237415477085\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     LogisticRegression())\n",
    "\n",
    "pipe.fit(train_X, train_y)\n",
    "p_preds = pipe.predict(val_X)\n",
    "\n",
    "print(\"Logistic Regression w/ Pipeline: \")\n",
    "print(accuracy_score(val_y, p_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5bd3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
